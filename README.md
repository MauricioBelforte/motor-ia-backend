# ğŸ§  chatbot-backend-vercel

Backend desacoplado, modular y serverless, listo para responder prompts IA desde cualquier frontend externo. Este motor fue extraÃ­do del proyecto original [`chatbot-flotante`](https://github.com/tu-usuario/chatbot-flotante), como parte de una estrategia tÃ©cnica de separaciÃ³n de responsabilidades y escalabilidad.

## ğŸ¯ PropÃ³sito

Este repositorio contiene la capa lÃ³gica y de procesamiento IA del sistema, separada del frontend visual. EstÃ¡ pensado para integrarse desde cualquier cliente mediante `fetch()`.

- ğŸ”„ Motor IA independiente del entorno visual
- ğŸ§ª Compatible con mÃºltiples proveedores como OpenRouter, Groq, Ollama
- ğŸ§° Listo para ser consultado por cualquier frontend, CMS o sistema externo
- ğŸŒ Desplegado en Vercel con rutas controladas

## âš™ï¸ Arquitectura

```text
chatbot-backend-vercel/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ chatbotApi.js       # Endpoint principal: procesa prompts y responde
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ consultasModelos.js       # LÃ³gica por modelo especÃ­fico
â”‚   â”œâ”€â”€ estadoOpenRouter.js       # Control dinÃ¡mico de disponibilidad
â”‚   â”œâ”€â”€ proveedores.js            # ConfiguraciÃ³n de proveedores
â”‚   â””â”€â”€ modelosPorProveedor.js    # Mapeo entre servicios y modelos
â”œâ”€â”€ vercel.json             # ConfiguraciÃ³n de rutas para deploy serverless
â”œâ”€â”€ .env                    # Claves privadas (no incluidas en este repo)
â”œâ”€â”€ LICENSE                 # Licencia MIT
â””â”€â”€ README.md               # Esta documentaciÃ³n ğŸ“˜
```

## ğŸ“¡ CÃ³mo consultarlo desde otro frontend

Ejemplo usando `fetch()`:

```js
const res = await fetch("https://chatbot-backend-vercel.vercel.app/api/chatbotApi", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    systemPrompt: "RespondÃ© como mentor tÃ©cnico.",
    userPrompt: "Â¿QuÃ© es un stream en JavaScript?"
  })
});
const { respuesta } = await res.json();
console.log(respuesta);
```

### ğŸ“„ Formato esperado del request

```json
{
  "systemPrompt": "Define el tono y rol del asistente",
  "userPrompt": "Mensaje original del usuario"
}
```

> âš ï¸ Este backend **no genera contexto**: espera que el cliente prepare los prompts.

## ğŸ§ª IA modular y tolerante a fallos

La carpeta `lib/` contiene toda la lÃ³gica desacoplada para interacciÃ³n con modelos de lenguaje:

- ğŸ“Š SelecciÃ³n de proveedor por disponibilidad
- ğŸ” Fallback automÃ¡tico en caso de error
- ğŸ§© OrganizaciÃ³n clara por servicio y modelo

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. ConsultÃ¡ el archivo [`LICENSE`](./LICENSE) para mÃ¡s detalles.

## ğŸ§­ Ecosistema completo

Este backend forma parte de un sistema modular junto al frontend visual embebible:

- ğŸ¨ Interfaz visual desacoplada: [`chatbot-frontend-embed`](https://github.com/tu-usuario/chatbot-frontend-embed)
- ğŸ“š Proyecto histÃ³rico original: [`chatbot-flotante`](https://github.com/tu-usuario/chatbot-flotante)

---

```bash
# VersiÃ³n actual: v1.0-backend
# Autor: Mauricio Belforte
```
```

---

