
## ğŸ§  motor-ia-backend

Backend desacoplado, modular y serverless, listo para responder prompts IA desde cualquier frontend externo. Este motor fue extraÃ­do del proyecto original [`chatbot-flotante`](https://github.com/MauricioBelforte/chatbot-flotante-historial) que actualmente se llama [`chatbot-flotante-historial`](https://github.com/MauricioBelforte/chatbot-flotante-historial), como parte de una estrategia tÃ©cnica de separaciÃ³n de responsabilidades y escalabilidad.

> ğŸŸ¢ *Renombrado desde `chatbot-backend-vercel` a `motor-ia-backend` para reflejar su propÃ³sito extendido como motor IA genÃ©rico, capaz de procesar cualquier consulta estructurada sin depender de un frontend especÃ­fico.*

---

## ğŸ¯ PropÃ³sito

Este repositorio contiene la capa lÃ³gica y de procesamiento IA del sistema, separada del frontend visual. EstÃ¡ pensado para integrarse desde cualquier cliente mediante `fetch()`:

- ğŸ”„ Motor IA independiente del entorno visual
- ğŸ§ª Compatible con mÃºltiples proveedores como OpenRouter, Groq, Ollama
- ğŸ§° Listo para ser consultado por cualquier frontend, CMS o sistema externo
- ğŸŒ Desplegado en Vercel con rutas controladas

---

## âš™ï¸ Arquitectura

```text
motor-ia-backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ chatbotApi.js            # Endpoint principal: procesa prompts y responde
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ consultasModelos.js      # LÃ³gica por modelo especÃ­fico
â”‚   â”œâ”€â”€ estadoOpenRouter.js      # Control dinÃ¡mico de disponibilidad
â”‚   â”œâ”€â”€ proveedores.js           # ConfiguraciÃ³n de proveedores
â”‚   â””â”€â”€ modelosPorProveedor.js   # Mapeo entre servicios y modelos
â”œâ”€â”€ vercel.json                  # ConfiguraciÃ³n de rutas para deploy serverless
â”œâ”€â”€ .env                         # Claves privadas (no incluidas en este repo)
â”œâ”€â”€ LICENSE                      # Licencia MIT
â””â”€â”€ README.md                    # Esta documentaciÃ³n ğŸ“˜
```

---

## ğŸ“¡ CÃ³mo consultarlo desde otro frontend

Ejemplo usando `fetch()`:

```js
const res = await fetch("https://motor-ia-backend.vercel.app/api/chatbotApi", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    systemPrompt: "RespondÃ© como mentor tÃ©cnico.",
    userPrompt: "Â¿QuÃ© es un stream en JavaScript?"
  })
});
const { respuesta } = await res.json();
console.log(respuesta);
```

### ğŸ“„ Formato esperado del request

```json
{
  "systemPrompt": "Define el tono y rol del asistente",
  "userPrompt": "Mensaje original del usuario"
}
```

> âš ï¸ Este motor **no genera contexto automÃ¡ticamente**: espera que el cliente prepare los prompts (por eso se llama â€œmotorâ€).

---

## ğŸ§ª IA modular y tolerante a fallos

La carpeta `lib/` contiene toda la lÃ³gica desacoplada para interacciÃ³n con modelos de lenguaje:

- ğŸ“Š SelecciÃ³n de proveedor por disponibilidad
- ğŸ” Fallback automÃ¡tico en caso de error
- ğŸ§© OrganizaciÃ³n clara por servicio y modelo
- âš™ï¸ Modularidad total para extender o cambiar proveedores sin alterar el nÃºcleo

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.  
ConsultÃ¡ el archivo [`LICENSE`](./LICENSE) para mÃ¡s detalles.

---

## ğŸ§­ Ecosistema completo

Este motor forma parte del ecosistema IA modular creado por Mauricio Belforte. EstÃ¡ diseÃ±ado para integrarse con frontends funcionales, demos personalizadas y otras herramientas IA:

- ğŸ¨ Frontend funcional: [`chatbot-frontend-funcional`](https://github.com/MauricioBelforte/chatbot-frontend-funcional)
- ğŸ’¬ Demo personalizada: [`demo-mi-chatbot-personal`](https://github.com/MauricioBelforte/demo-mi-chatbot-personal)
- ğŸ“š CÃ¡psula tÃ©cnica original: [`chatbot-flotante-historial`](https://github.com/MauricioBelforte/chatbot-flotante-historial)

---

```bash
# VersiÃ³n actual: v1.1-motor
# Autor: Mauricio Belforte
```

---

